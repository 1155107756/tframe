from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import six
import tensorflow as tf
import tframe as tfr
from tframe import checker


def _truncate(truth, output):
  # TODO: only supported for some metrics
  assert len(truth.shape.as_list()) > 2
  i = tf.cond(tf.get_collection(tfr.pedia.is_training)[0],
              lambda: 0, lambda: tfr.hub.val_preheat)
  return truth[:, i:], output[:, i:]


def summary_wrapper(f, last_only):
  assert callable(f)
  checker.check_type(last_only, bool)

  def _wrapper(tensor1, tensor2, *args, **kwargs):
    assert isinstance(tensor1, tf.Tensor) and isinstance(tensor2, tf.Tensor)
    metric_detail, summ_f = f(tensor1, tensor2, *args, **kwargs)
    assert callable(summ_f)
    # Add detail to collection for batch evaluation
    tf.add_to_collection(tfr.pedia.metric_foreach, metric_detail)
    # For n to 1 RNN models
    if last_only: metric_detail = metric_detail[:, -1]
    return summ_f(metric_detail)
  return _wrapper


# region : General Metrics

# TODO: to be deprecated
def __seq_acc(summary, outputs):
  """
  Sequence accuracy: a metric for sequence classification task
  TODO: can not be used with parallel engine
  :param summary: an tf.Tensor of shape
                  (batch, 1 or num_steps, 1 or num_classes), usually provided
                  by summ_dict of a DataSet
  :param outputs: an tf.Tensor of shape (batch, num_steps, 1 or num_classes),
                  generated by model.
  """
  # Check input
  assert isinstance(summary, tf.Tensor) and isinstance(outputs, tf.Tensor)
  assert len(summary.shape) == len(outputs.shape) == 3
  # Convert labels and outputs to dense tensors
  tensors = [summary, outputs]
  for i, tensor in enumerate(tensors):
    shape = tensor.shape.as_list()
    # Convert to dense if necessary
    if shape[-1] > 1:
      tensor = tf.argmax(
        tensor, -1, name='summary' if i == 0 else 'predictions')
      # Put tensor back to list
      tensors[i] = tensor

  correct_prediction = tf.cast(tf.equal(tensors[0], tensors[1]), tf.float32)
  tf.add_to_collection(tfr.pedia.metric_foreach, correct_prediction)
  return tf.reduce_mean(correct_prediction[:, -1], name='seq_accuracy')

def accuracy(pred_thres=None):
  return lambda l, o: _accuracy(l, o, pred_thres)

def _accuracy(labels, outputs, pred_thres=None):
  """
  labels are provided by data_set, outputs are generated by model
  For FNN, outputs.shape = (batch, [*sample_shape], num_classes)
  For RNN, outputs.shape = (batch, num_steps, num_classes)

  :param pred_thres: The prediction threshold.
  """
  # Make sure labels and outputs are tensorflow tensors
  assert isinstance(labels, tf.Tensor) and isinstance(outputs, tf.Tensor)
  # Truncate data if necessary TODO: maybe its not safe
  # RNN outputs usually have a dimension larger than 2
  if len(labels.shape) > 2 and tfr.hub.val_preheat > 0:
    labels, outputs = _truncate(labels, outputs)

  # Convert labels and outputs to 2-D dense tensors
  tensors = [labels, outputs]
  for i, tensor in enumerate(tensors):
    shape = tensor.shape.as_list()
    # RNN outputs has a shape length of 3
    # Image segmentation results have a shape of 4 dims
    # assert len(shape) in (2, 3, 4)
    # Convert one-hot to dense if necessary
    if shape[-1] > 1:
      # tensor = tf.argmax(tensor, -1, name='labels' if i == 0 else 'predictions')
      tensor = tf.argmax(tensor, -1)
    # Put tensor back to list
    # tensors[i] = tensor
    if pred_thres is None:
      tensors[i] = tf.round(tensor, name='labels' if i == 0 else 'predictions')

  # Prepare fetcher for model's batch operations
  if pred_thres is None:
    correct_prediction = tf.equal(tensors[0], tensors[1])
  else:
    assert pred_thres > 0
    abs_delta = tf.abs(tensors[0] - tensors[1])
    correct_prediction = tf.greater_equal(pred_thres, abs_delta)
  correct_prediction = tf.cast(correct_prediction, tf.float32)
  return correct_prediction, tf.reduce_mean
  # tf.add_to_collection(tfr.pedia.metric_foreach, correct_prediction)
  #
  # # Return accordingly
  # if last_only: return tf.reduce_mean(correct_prediction[:, -1], name='seq_acc')
  # else: return tf.reduce_mean(correct_prediction, name='accuracy')

def generalized_accuracy(truth, output):
  """This metric is first designed for ERG data set, for whom models are
     built with outputs of shape [1, string_len, symbol_number]"""
  # Sanity check
  assert isinstance(truth, tf.Tensor) and isinstance(output, tf.Tensor)
  truth_shape = truth.shape.as_list()
  output_shape = output.shape.as_list()

  # Assert batch size is 1
  # assert truth_shape[0] == output_shape[0] == 1
  assert len(truth_shape) == len(output_shape) == 3
  assert truth_shape[-1] == output_shape[-1] > 1
  # truth = tf.reshape(truth, truth_shape[1:])
  # output = tf.reshape(output, output_shape[1:])

  # Compare distribution
  # TODO: consider tf.nn.top_k or something
  tf_sort = lambda val: tf.contrib.framework.sort(
    val, axis=2, direction='DESCENDING')

  alpha = tf.reduce_sum(tf.multiply(truth, output), axis=2)
  beta = tf.reduce_sum(tf.multiply(tf_sort(truth), tf_sort(output)), axis=2)

  metric_foreach = tf.cast(tf.equal(alpha, beta), tf.float32)
  return metric_foreach, tf.reduce_mean
  # tf.add_to_collection(tfr.pedia.metric_foreach, metric_foreach)
  # return tf.reduce_mean(metric_foreach)

def mse(truth, output):
  return tf.square(truth - output), tf.reduce_mean

# endregion : General Metrics

# region : Metrics for FNN only

def delta(truth, output):
  assert isinstance(truth, tf.Tensor) and isinstance(output, tf.Tensor)
  if tfr.hub.val_preheat > 0:
    truth, output = _truncate(truth, output)
  return tf.norm(truth - output)

def norm_error_ratio(truth, output):
  assert isinstance(truth, tf.Tensor) and isinstance(output, tf.Tensor)
  if tfr.hub.val_preheat > 0:
    truth, output = _truncate(truth, output)
  return tf.norm(truth - output) / tf.norm(truth) * 100

def rms_error_ratio(truth, output):
  assert isinstance(truth, tf.Tensor) and isinstance(output, tf.Tensor)
  rms = lambda x: tf.sqrt(tf.reduce_mean(tf.square(x)))
  # TODO: pilot, tfr.hub.val_preheat > 0 only happens in RNN model
  #       thus output.shape is [batch_size, step_num, *target_shape]
  if tfr.hub.val_preheat > 0:
    truth, output = _truncate(truth, output)
  return rms(truth - output) / rms(truth) * 100

def rms_error_in_mv(truth, output):
  assert isinstance(truth, tf.Tensor) and isinstance(output, tf.Tensor)
  rms = lambda x: tf.sqrt(tf.reduce_mean(tf.square(x)))
  return 1000 * rms(truth - output)

# endregion : Metrics for FNN only

def get(identifier, last_only=False, pred_thres=None, **kwargs):
  if callable(identifier):
    return identifier

  elif isinstance(identifier, six.string_types):
    identifier = identifier.lower()

    if identifier in ['accuracy', 'acc']:
      f = accuracy(pred_thres)
    elif identifier in ['seq_acc', 'seq_accuracy']:
      f = accuracy(pred_thres)
      last_only = True
    elif identifier in ['mse']:
      f = mse
    elif identifier in ['delta', 'distance']:
      return delta
    elif identifier in ['ratio', 'norm_ratio']:
      return norm_error_ratio
    elif identifier in ['rms_ratio']:
      return rms_error_ratio
    elif identifier in ['rms_mv']:
      return rms_error_in_mv
    else:
      raise ValueError('Can not resolve "{}"'.format(identifier))

    return summary_wrapper(f, last_only)
  else:
    raise TypeError('identifier must be a function or a string')



